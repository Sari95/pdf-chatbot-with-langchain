#!/usr/bin/env python

import streamlit as st
from core import build_qa_chain


def main():
    """
    Simple web-based user interface for the PDF chatbot using Streamlit

    The UI allows users to ask questions about a PDF document and get answers generated by a local LLM (via Ollama) - combined with RAG.
    """
    st.set_page_config(page_title="ğŸ“„ PDF-Chatbot", layout="wide")
    st.title("ğŸ“„ Chat with your PDF")

    qa_chain = build_qa_chain("example.pdf")  # Builds the QA chain using the specified PDF file

    # Initializes the chat history in Streamlit's session state
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # Creates a text input field for the user to ask a question
    question = st.text_input("What would you like to know?", key="input")

    # If a question is submitted, the question is sent to the QA chain & stores the result
    if question:
        result = qa_chain({"question": question, "chat_history": st.session_state.chat_history})

        st.session_state.chat_history.append(
            (question, result["answer"])
        )  # Saves the question & the answer to the session history

        # Displays the chat history in reverse order (newest on top)
        for i, (q, a) in enumerate(st.session_state.chat_history[::-1]):
            st.markdown(f"**â“ Question {len(st.session_state.chat_history) - i}:** {q}")
            st.markdown(f"**ğŸ¤– Answer:** {a}")


if __name__ == "__main__":
    main()
